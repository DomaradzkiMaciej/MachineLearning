{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeRy_Ng0lfDT"
   },
   "source": [
    "<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n",
    "\n",
    "AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n",
    "<hr>\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n",
    "\n",
    "<center>\n",
    "Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego \n",
    "Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n",
    "Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\" \n",
    "Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n",
    "    </center>\n",
    "\n",
    "**Author: Tomasz Pawłowski**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uEERM15Z3i6"
   },
   "source": [
    "# ML in big scale - LAB 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ao9tweXeZr_i"
   },
   "source": [
    "Plan\n",
    "\n",
    "1. Setting up pyspark\n",
    "2. Map-Reduce word count example\n",
    "3. Map-Reduce exercises\n",
    "4. Homework\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5XTROAjE7ek"
   },
   "source": [
    "To **edit the colab** first copy it to your drive with the top bars `File -> Save a copy on drive` option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdrOqKrbbWEi"
   },
   "source": [
    "## Setting up PySpark\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sxqy7fQ2Zn_u",
    "outputId": "24cc6e53-69c4-4956-d961-e6e6a92cfc46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 281.3 MB 41 kB/s \n",
      "\u001b[K     |████████████████████████████████| 199 kB 49.2 MB/s \n",
      "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark --quiet\n",
    "!pip install -U -q PyDrive --quiet \n",
    "!apt install openjdk-8-jdk-headless &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hvP2cvhBb-gi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IRX13sVIcU9Z"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().set('spark.ui.port', '4050').setAppName(\"mlibs\").setMaster(\"local[2]\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fC4mnbWTYtkH"
   },
   "source": [
    "Note: pyspark documentation is [here](https://spark.apache.org/docs/3.1.2/api/python/reference/index.html). For example: list of `SparkContext` methods is [here](https://spark.apache.org/docs/3.1.2/api/python/reference/pyspark.html#spark-context-apis).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGTb1EnMFy9U"
   },
   "source": [
    "## Example: Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckyobZb8ZtJT"
   },
   "source": [
    "*Loading* data to clusters RAM. In spark such distributed datasets are called [RDD](https://spark.apache.org/docs/latest/rdd-programming-guide.html#resilient-distributed-datasets-rdds). They are divided into partitions which can be processed independently by different workers.\n",
    "\n",
    "`RDD` can be created from python collection, or by loading data from a file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUtLR5z2dUNv"
   },
   "source": [
    "### From python iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_NdrZeQNO5v",
    "outputId": "e3e4f70c-c961-4699-b66b-c20b87620621"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2], [3], [4, 5]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_partitions = 4\n",
    "\n",
    "array_of_numbers = [1, 2, 3, 4, 5]\n",
    "rdd_of_numbers = sc.parallelize(array_of_numbers, number_of_partitions)\n",
    "\n",
    "# `glom` shows how data is distributed in partitions\n",
    "rdd_of_numbers.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkQdwLSvdayo"
   },
   "source": [
    "### From google drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scY25PLEZrM1"
   },
   "source": [
    "Loading data from google drive. Based on [tutorial](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=eFOvsAYk1tcH). Note that loading from google drive is useful but not required for this lab. You can also upload files to colab using the left menu bars `Files` menu, but such files are not persisted.\n",
    "\n",
    "Note that using google drive from other account that from which you open notebooks may not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iV7TE2B_Pk7t"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K8X6wp8g3frp"
   },
   "source": [
    "Your google drive should now be mounted in the `/content/drive/My Drive/` local directory of this colab. \n",
    "\n",
    "The next code fragment assumes that you have there the following directory/file: `dir_on_my_drive/input.txt`. There is no file `input.txt`, you can create an empty one. This is just an example how to use p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jb9DBoKnRuSF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# first upload input.txt to your gdrive!\n",
    "path = \"/content/drive/My Drive/dir_on_my_drive/input.txt\"\n",
    "if os.path.isfile(path):\n",
    "  lines_from_drive_file = sc.textFile(path)\n",
    "  print(lines_from_drive_file.collect())\n",
    "  # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMI04msQQbsD"
   },
   "outputs": [],
   "source": [
    "drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsjREihyddzp"
   },
   "source": [
    "### From online resource "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI7qa_-XFj5a"
   },
   "source": [
    "Downloading data to colab (machine executing the colab's) from an online source can be done using `wget` shell tool. Note the exclamation mark (!) before the command which indicates that this line should be executed by shell not python.\n",
    "\n",
    "Note that such downloaded files are not persisted. They are deleted after closing the colab session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FTXB7EFbWVug"
   },
   "outputs": [],
   "source": [
    "!wget -q https://wolnelektury.pl/media/book/txt/balladyna.txt -O sample_data/balladyna.txt\n",
    "!wget -q https://wolnelektury.pl/media/book/txt/zemsta.txt -O sample_data/zemsta.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFl3cdp3eZnF"
   },
   "source": [
    "After downloading such files are visible in left menu bars `Files` section in `sample_data` directory.\n",
    "\n",
    "They can be accessed from python code using path: `sample_data/balladyna.txt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tPyvvCqOgZcf",
    "outputId": "4ead64d4-c00f-4d99-c5c0-4ad0dc619f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Juliusz Słowacki\n",
      "1: \n",
      "2: Balladyna\n",
      "3: Tragedia w pięciu aktach\n",
      "4: \n",
      "5: ISBN 978-83-288-2852-0\n",
      "6: \n",
      "7: \n",
      "8: \n",
      "9: \n",
      "10: KOCHANY POETO RUIN!\n",
      "11: \n",
      "12: Pozwól, że pisząc do ciebie zacznę od apologu, który mi opowiedziano nad Salaminy zatoką.\n",
      "13: \n",
      "14: Stary i ślepy harfiarz z wyspy Scio przyszedł nad brzegi Morza Egejskiego, a usłyszawszy z wielkim hukiem łamiące się fale; myślał, że szum ów pochodził od zgiełku ludzi, którzy się zbiegli pieśni rycerskich posłuchać. — Oparł się więc na harfie i śpiewał pustemu morza brzegowi: a kiedy skończył, zadziwił się, że żadnego ludzkiego głosu, żadnego westchnienia, żadnego pieśń nie zyskała oklasku. Rzucił więc harfę precz daleko od siebie, a te fale, które śpiewak mniemał tłumem ludzkim, odniosły złote pieśni narzędzie i położyły mu je przy stopach. I odszedł od harfy swojej smutny Greczyn nie wiedząc, że najpiękniejszy rapsod nie w sercach ludzi, ale w głębi fal Egejskiego Morza utonął.\n",
      "15: \n",
      "16: Kochany Irydionie! ta powiastka o falach i harfiarzu zastąpi wszelką do Balladyny przemowę. Wychodzi na świat Balladyna z ariostycznym uśmiechem na twarzy, obdarzona wnętrzną siłą urągania się z tłumu ludzkiego, z porządku i z ładu, jakim się wszystko dzieje na świecie, z nieprzewidzianych owoców, które wydają drzewa ręką ludzi szczepione. Niech naprawiacz wszelkiego bezprawia Kirkor pada ofiarą swoich czystych zamiarów; niech Grabieć miłuje kuchnią Kirkora; niechaj powietrzna Goplana kocha się w rumianym chłopie, a sentymentalny Filon szuka umyślnie męczarni miłosnych i umarłej kochanki; niechaj tysiące anachronizmów przerazi śpiących w grobie historyków i kronikarzy: a jeżeli to wszystko ma wnętrzną siłę żywota, jeżeli stworzyło się w głowie poety podług praw boskich, jeżeli natchnienie nie było gorączką, ale skutkiem tej dziwnej władzy, która szepce do ucha nigdy wprzód nie słyszane wyrazy, a oczom pokazuje nigdy, we śnie nawet, nie widziane istoty; jeżeli instynkt poetyczny był lepszym od rozsądku, który nieraz tę lub ową rzecz potępił: to Balladyna wbrew rozwadze i historii zostanie królową polską — a piorun, który spadł na jej chwilowe panowanie, błyśnie i roztworzy mgłę dziejów przeszłości.\n"
     ]
    }
   ],
   "source": [
    "with open('sample_data/balladyna.txt', 'r') as f:\n",
    "  for i, line in enumerate(f.readlines()):\n",
    "    print(f\"{i}: {line}\", end='')\n",
    "    if i > 15:\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueSDCFgXgObp"
   },
   "source": [
    "## Example: Saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGE-2xzXq4Eq"
   },
   "source": [
    "There are multiple save methods in [RDD API](https://spark.apache.org/docs/3.1.2/api/python/reference/pyspark.html#rdd-apis)\n",
    "\n",
    "Here are some examples. After executing following two code examples check how the data is formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "349UWuCfro3h"
   },
   "outputs": [],
   "source": [
    "# Saving as text file\n",
    "\n",
    "sc.parallelize([('a', 1), ('b', 2), ('c', 0), ('d', 1), ('e', 0)], 2).saveAsTextFile('save_example1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UFxymwAVrpYm"
   },
   "outputs": [],
   "source": [
    "# Saving as pickle\n",
    "\n",
    "sc.parallelize([('x', 1), ('y', 2), ('z', 0), ('w', 1), ('ź', 4)], 2).saveAsPickleFile('save_example2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YChu20IpspmC"
   },
   "source": [
    "Note that partitions are saved separately in their own directoires.\n",
    "\n",
    "Loading of pickled files is straightforward. For text files it can be loaded with [textFile](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.SparkContext.textFile.html#pyspark.SparkContext.textFile) but requires manual parsing. `glom` method used below visualizes how data is split between partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ucVBwxDvspON",
    "outputId": "815f4753-1d71-4b58-848f-9068e2d85b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('z', 0), ('w', 1), ('ź', 4)], [('x', 1), ('y', 2)]]\n"
     ]
    }
   ],
   "source": [
    "print(sc.pickleFile('save_example2').glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtjIWtBidwxi"
   },
   "source": [
    "## Map-Reduce sample interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjzWTWa8LJET"
   },
   "source": [
    "You don't need to understand it, yet. Just execute this cell. The `map_reduce` method will be used in the following examples and exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XpIFGtSEE3rb"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import operator\n",
    "from pyspark import RDD\n",
    "from typing import Callable, Iterable, List, Tuple, TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "U = TypeVar('U')\n",
    "V = TypeVar('V')\n",
    "S = TypeVar('S')\n",
    "\n",
    "def map_reduce(\n",
    "    input: RDD[T], \n",
    "    map_function: Callable[[T], Iterable[Tuple[U, V]]], \n",
    "    reduce_function: Callable[[U, Iterable[V]], Iterable[S]],\n",
    "    combiner_function: Callable[[U, Iterable[V]], V] = None\n",
    "    ) -> RDD[S]:\n",
    "\n",
    "  mapped_rdd = input.flatMap(map_function, preservesPartitioning=True)\n",
    "\n",
    "  if combiner_function is not None:\n",
    "    def apply_combiner(partition: Iterable[Tuple[U, V]]) -> Iterable[Tuple[U, V]]:\n",
    "      it = itertools.groupby(partition, operator.itemgetter(0))\n",
    "      for key, values in it:\n",
    "        yield key, combiner_function(key, (v for _, v in values))\n",
    "\n",
    "    mapped_rdd = mapped_rdd.mapPartitions(apply_combiner, preservesPartitioning=True)\n",
    "\n",
    "  return mapped_rdd\\\n",
    "      .groupByKey()\\\n",
    "      .flatMap(lambda k_v: reduce_function(k_v[0], k_v[1]), preservesPartitioning=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjvTXPpQNH2M"
   },
   "source": [
    "## Example: Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GS8BomsYXKJL",
    "outputId": "94b91819-b01f-4180-ca61-2609afdef171"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Juliusz Słowacki',\n",
       " '',\n",
       " 'Balladyna',\n",
       " 'Tragedia w pięciu aktach',\n",
       " '',\n",
       " 'ISBN 978-83-288-2852-0',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'KOCHANY POETO RUIN!',\n",
       " '',\n",
       " 'Pozwól, że pisząc do ciebie zacznę od apologu, który mi opowiedziano nad Salaminy zatoką.',\n",
       " '',\n",
       " 'Stary i ślepy harfiarz z wyspy Scio przyszedł nad brzegi Morza Egejskiego, a usłyszawszy z wielkim hukiem łamiące się fale; myślał, że szum ów pochodził od zgiełku ludzi, którzy się zbiegli pieśni rycerskich posłuchać. — Oparł się więc na harfie i śpiewał pustemu morza brzegowi: a kiedy skończył, zadziwił się, że żadnego ludzkiego głosu, żadnego westchnienia, żadnego pieśń nie zyskała oklasku. Rzucił więc harfę precz daleko od siebie, a te fale, które śpiewak mniemał tłumem ludzkim, odniosły złote pieśni narzędzie i położyły mu je przy stopach. I odszedł od harfy swojej smutny Greczyn nie wiedząc, że najpiękniejszy rapsod nie w sercach ludzi, ale w głębi fal Egejskiego Morza utonął.',\n",
       " '',\n",
       " 'Kochany Irydionie! ta powiastka o falach i harfiarzu zastąpi wszelką do Balladyny przemowę. Wychodzi na świat Balladyna z ariostycznym uśmiechem na twarzy, obdarzona wnętrzną siłą urągania się z tłumu ludzkiego, z porządku i z ładu, jakim się wszystko dzieje na świecie, z nieprzewidzianych owoców, które wydają drzewa ręką ludzi szczepione. Niech naprawiacz wszelkiego bezprawia Kirkor pada ofiarą swoich czystych zamiarów; niech Grabieć miłuje kuchnią Kirkora; niechaj powietrzna Goplana kocha się w rumianym chłopie, a sentymentalny Filon szuka umyślnie męczarni miłosnych i umarłej kochanki; niechaj tysiące anachronizmów przerazi śpiących w grobie historyków i kronikarzy: a jeżeli to wszystko ma wnętrzną siłę żywota, jeżeli stworzyło się w głowie poety podług praw boskich, jeżeli natchnienie nie było gorączką, ale skutkiem tej dziwnej władzy, która szepce do ucha nigdy wprzód nie słyszane wyrazy, a oczom pokazuje nigdy, we śnie nawet, nie widziane istoty; jeżeli instynkt poetyczny był lepszym od rozsądku, który nieraz tę lub ową rzecz potępił: to Balladyna wbrew rozwadze i historii zostanie królową polską — a piorun, który spadł na jej chwilowe panowanie, błyśnie i roztworzy mgłę dziejów przeszłości.',\n",
       " '',\n",
       " 'Uśmiechnij się teraz, Irydionie, bo oto naśladując francuskich poetów: powiem ci, że Balladyna jest tylko epizodem wielkiego poematu w rodzaju Ariosta, który ma się uwiązać z sześciu tragedii, czyli kronik dramatycznych. Cienił już różne ludzi niebyłych wyszły ze mgły przedstworzenia i otaczają mnie ciżbą gwarzącą: potrzeba tylko, aby się zebrały w oddzielne tłumy, ażeby czyny ich ułożyły się w postacie piramidalne wypadków, a jedną po drugiej garstkę na świat wypychać będę; i sprawdzą się może sny mego dzieciństwa. Bo ileż to razy patrząc na stary zamek, koronujący ruinami górę mego rodzinnego miasteczka, marzyłem, że kiedyś w ten wieniec wyszczerbionych murów nasypię widm, duchów, rycerzy; że odbuduję upadłe sale i oświecę je przez okna ogniem piorunowych nocy, a sklepieniom każę powtarzać dawne Sofoklesowskie „niestety!” A za to imię moje słyszane będzie w szumie płynącego pod górą potoku, a jakaś niby tęcza z myśli moich unosić się będzie nad ruinami zamku. — O! nie mów mi, że z dzwonków polnych większa ozdoba ruinom niż z tego wieńca myśli, w który je ubierze poeta: — bo choć róże rosnące na ruinach pałacu Nerona rozwidniały nam pięknie te gruzy: to jednak jaśniej mi je oświecił ów duch Irydiona, któregoś ty pod krzyżem w Kolosseum położył i nakrył złotymi skrzydłami anioła.',\n",
       " '']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_from_file = sc.textFile('sample_data/balladyna.txt')\n",
    "\n",
    "lines_from_file.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73dh_irCXScy",
    "outputId": "13c6bc7a-9c0d-477c-ec88-3e3055377e7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['juliusz',\n",
       " 'słowacki',\n",
       " 'balladyna',\n",
       " 'tragedia',\n",
       " 'w',\n",
       " 'pięciu',\n",
       " 'aktach',\n",
       " 'isbn',\n",
       " '978-83-288-2852-0',\n",
       " 'kochany',\n",
       " 'poeto',\n",
       " 'ruin!',\n",
       " 'pozwól,',\n",
       " 'że',\n",
       " 'pisząc',\n",
       " 'do',\n",
       " 'ciebie',\n",
       " 'zacznę',\n",
       " 'od',\n",
       " 'apologu,',\n",
       " 'który',\n",
       " 'mi',\n",
       " 'opowiedziano',\n",
       " 'nad',\n",
       " 'salaminy',\n",
       " 'zatoką.',\n",
       " 'stary',\n",
       " 'i',\n",
       " 'ślepy',\n",
       " 'harfiarz']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "example_words = lines_from_file.flatMap(lambda line: filter(None, re.split(r'\\s+', line.lower())))\n",
    "\n",
    "example_words.take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1a4WzjZQR2n",
    "outputId": "4e98dbb5-4905-4383-e6d2-4611c3c65d95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('juliusz', 3),\n",
       " ('balladyna', 263),\n",
       " ('kochany', 2),\n",
       " ('ruin!', 1),\n",
       " ('pozwól,', 2),\n",
       " ('do', 229),\n",
       " ('zacznę', 1),\n",
       " ('apologu,', 1),\n",
       " ('mi', 89),\n",
       " ('salaminy', 1),\n",
       " ('i', 518),\n",
       " ('ślepy', 1),\n",
       " ('harfiarz', 1),\n",
       " ('scio', 1),\n",
       " ('przyszedł', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import RDD\n",
    "from typing import Tuple \n",
    "\n",
    "def word_count(words_rdd: RDD[str]) -> RDD[Tuple[str, int]]:\n",
    "  return map_reduce(\n",
    "      words_rdd, \n",
    "      lambda word: [(word, 1)], \n",
    "      lambda k, vs: [(k, sum(vs))]\n",
    "  )\n",
    "\n",
    "word_count(example_words).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40Y4901oXShP",
    "outputId": "28bfe6d9-b510-4847-f443-7e3dba09d10e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('juliusz', 3),\n",
       " ('balladyna', 263),\n",
       " ('kochany', 2),\n",
       " ('ruin!', 1),\n",
       " ('pozwól,', 2),\n",
       " ('do', 229),\n",
       " ('zacznę', 1),\n",
       " ('apologu,', 1),\n",
       " ('mi', 89),\n",
       " ('salaminy', 1),\n",
       " ('i', 518),\n",
       " ('ślepy', 1),\n",
       " ('harfiarz', 1),\n",
       " ('scio', 1),\n",
       " ('przyszedł', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_count_with_combiner(words_rdd: RDD[str]) -> RDD[Tuple[str, int]]:\n",
    "  return map_reduce(\n",
    "      words_rdd,\n",
    "      lambda word: [(word, 1)], \n",
    "      lambda k, vs: [(k, sum(vs))],\n",
    "      lambda _, vs: sum(vs)\n",
    "  )\n",
    "\n",
    "word_count_with_combiner(example_words).take(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYx8dsk2gJY0"
   },
   "source": [
    "## Exercise 1: Average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iusCF9B6gFsk"
   },
   "source": [
    "Calculate average for given `RDD` of numbers. Use `map_reduce` utility method. Try to add a combiner function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xFkFGAy1ba0k"
   },
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "def average_without_combiner(numbers_rdd: RDD[Union[int, float]]) -> float:\n",
    "  if numbers_rdd.isEmpty():\n",
    "    return float('NaN')\n",
    "\n",
    "  return map_reduce(\n",
    "      numbers_rdd,\n",
    "      lambda n: [(None, (n, 1))],\n",
    "      lambda k, vs: [(lambda values, counts: sum(values) / sum(counts))(*zip(*vs))]\n",
    "      ).collect()[0]\n",
    "  \n",
    "def average_with_combiner(numbers_rdd: RDD[Union[int, float]]) -> float:\n",
    "  if numbers_rdd.isEmpty():\n",
    "    return float('NaN')\n",
    "\n",
    "  return map_reduce(\n",
    "      numbers_rdd,\n",
    "      lambda n: [(None, (n, 1))],\n",
    "      lambda k, vs: [(lambda values, counts: sum(values) / sum(counts))(*zip(*vs))],\n",
    "      lambda _, vs: (lambda values, counts: (sum(values), sum(counts)))(*zip(*vs))\n",
    "      ).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cuALAexNiZiE",
    "outputId": "9b85d49c-b355-4a97-d0d7-a392741f114a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5, 27.0, nan]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    average_with_combiner(sc.parallelize([1,2,3,4,5,6])), # should be 3.5\n",
    "    average_with_combiner(sc.parallelize([42, 12])),      # should be 27 or 27.0\n",
    "    average_with_combiner(sc.parallelize([]))             # NaN or raise a meaningful exception \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxZLm_9yf8Tq"
   },
   "source": [
    "## Exercise 2: Jaccard similarity coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVtmXbH7gBr5"
   },
   "source": [
    "Compute [Jaccard similarity coefficient](https://en.wikipedia.org/wiki/Jaccard_index) of two sets given by two RDD-s. Note: [union](https://spark.apache.org/docs/3.1.2/api/python/reference/api/pyspark.SparkContext.union.html#pyspark.SparkContext.union) function may be needed. Use either `map_reduce` utility function or `map`, `flatMap`, `groupByKey` or other methods from [RDD](https://spark.apache.org/docs/3.1.2/api/python/reference/pyspark.html#rdd-apis) directly.\n",
    "\n",
    "You can assume that both given `RDD`-s do not contain any duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "U3xJIjLbvSzN"
   },
   "outputs": [],
   "source": [
    "from pyspark import RDD\n",
    "from typing import TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def jaccard_similarity(a: RDD[T], b: RDD[T]) -> float:\n",
    "  if a.isEmpty() and b.isEmpty():\n",
    "    return float('NaN')\n",
    "\n",
    "  union = a.map(lambda x: (x, 'A'), preservesPartitioning=True)\\\n",
    "      .union(b.map(lambda x: (x, 'B'), preservesPartitioning=True))\n",
    "\n",
    "  elements_in_common, elements_in_sum = union.groupByKey().mapValues(len).aggregate(\n",
    "      (0, 0),\n",
    "      lambda x, y: ((x[0] + 1) if y[1] == 2 else x[0], x[1] + 1),\n",
    "      lambda x, y: (x[0] + y[0], x[1] + y[1])\n",
    "  )\n",
    "\n",
    "  return elements_in_common / elements_in_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHPlSeV4hi8-",
    "outputId": "11a2b9e9-55e4-4be4-d300-faaef4b4083f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.0, 0.5, nan]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    jaccard_similarity(sc.parallelize([1,2,3]), sc.parallelize([2,3,4])), # 0.5\n",
    "    jaccard_similarity(sc.parallelize([1,2,3]), sc.parallelize([4,5])), # 0.0\n",
    "    jaccard_similarity(sc.parallelize(['a', 'b', 'c', 'd']), sc.parallelize(['c', 'b'])), # 0.5\n",
    "    jaccard_similarity(sc.parallelize([]), sc.parallelize([])) # NaN or raise a meaningful exception\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_tNZYbN8Y1c"
   },
   "source": [
    "## Exercise 3: Fetching online data\n",
    "\n",
    "Distribute fetching definitions of words from an online resource [Słownik języka polskiego](https://sjp.pl).\n",
    "\n",
    "Cell below downloads a database of words tagged as acceptable in word games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7koSvgJL-Rs3",
    "outputId": "434b7b66-c14a-4934-db1a-6a1fcd8fe246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  sample_data/sjp-20221023.zip\n",
      "  inflating: sample_data/slowa.txt   \n"
     ]
    }
   ],
   "source": [
    "!wget -q https://sjp.pl/sl/growy/sjp-20221023.zip -O sample_data/sjp-20221023.zip\n",
    "!rm -f sample_data/slowa.txt\n",
    "!unzip sample_data/sjp-20221023.zip slowa.txt -d sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oed74atC_hyl",
    "outputId": "d04362e8-1a3f-4d3f-8f72-6a480f3aced4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aaa', 'aalborscy', 'aalborska', 'aalborską', 'aalborski', 'aalborskich', 'aalborskie', 'aalborskiego', 'aalborskiej', 'aalborskiemu', 'aalborskim', 'aalborskimi', 'aalborsko', 'aalborsku']\n",
      "['bajzelek', 'deprecho', 'elektryzacyj', 'eudajmonią', 'męczylibyśmy', 'niepopsoceniom', 'niewydumywania', 'obsypcież', 'obyczajowych', 'oplewiałabyś', 'romancy', 'rozwlekana', 'sekstaśmą', 'subwencjonujcie', 'trzepotem', 'zabałamucę', 'związani']\n"
     ]
    }
   ],
   "source": [
    "# prints example values\n",
    "\n",
    "words_rdd = sc.textFile('sample_data/slowa.txt')\n",
    "print(words_rdd.take(15))\n",
    "\n",
    "words_sample_rdd = words_rdd.sample(False, 20.0/words_rdd.count())\n",
    "print(words_sample_rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaPL_0t4v6yy"
   },
   "source": [
    "Next cell shows how to download definitions of the word from the same source by parsing a html webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BgRpva3QA04-",
    "outputId": "2631a102-9595-46ea-a527-a824fbd476da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. rodzaj pisemnego sprawdzianu, egzamin; zestaw odpowiednio przygotowanych pytań;\\n2. badanie, próba;\\n3. kontrolny obraz w odbiorniku telewizyjnym', 'partia wokalna w oratoriach, pełniąca funkcję narratora objaśniającego tło akcji i zaistniałą sytuację dramatyczną']\n",
      "['wyrażenie mające na celu zasygnalizowanie swojej obecności osobie niespodziewającej się tego']\n"
     ]
    }
   ],
   "source": [
    "from pyspark import RDD\n",
    "import re\n",
    "import ssl\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def fetch_definition(word: str) -> Iterable[str]:\n",
    "  definition_re = re.compile(r\"<p style=\\\"margin: \\.5em 0; font: medium[^\\\"]*\\\">([^<]+(?:<br />[^<]+)*)</p>\")\n",
    "  url = f\"https://sjp.pl/{urllib.parse.quote(word)}\"\n",
    "  response = urllib.request.urlopen(url, context=ssl._create_unverified_context())\n",
    "  html = response.read().decode(response.headers.get_content_charset())\n",
    "  return (d.group(1).replace('<br />', \"\\n\") for d in definition_re.finditer(html))\n",
    "  \n",
    "print(list(fetch_definition(\"test\")))\n",
    "print(list(fetch_definition(\"a kuku\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3_ymcgnwd5y"
   },
   "source": [
    "Using our `map_reduce` method and the function above a method that distributes downloading of the definitions of words can be created. Implement it as an exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "kO_R6uRlw8cL"
   },
   "outputs": [],
   "source": [
    "def fetch_definitions(rdd: RDD[str]) -> RDD[Tuple[str, str]]:\n",
    "  return map_reduce(\n",
    "      rdd.repartition(12),\n",
    "      lambda word: [(word, None)], \n",
    "      lambda word, _: [(word, definition) for definition in fetch_definition(word)]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RxMsArg8H2nV",
    "outputId": "ebb47b6e-9b5d-416a-abcd-a0f23025991b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eudajmonią\n",
      "  w starożytnej etyce: pełnia osobistego szczęścia, poczucie spełnienia wynikające z godnego życia; eudemonia\n",
      "\n",
      "niepopsoceniom\n",
      "  spędzić pewien czas na psoceniu; pobroić, porozrabiać, połobuzować\n",
      "\n",
      "sekstaśmą\n",
      "  amatorskie nagranie stosunku seksualnego\n",
      "\n",
      "zabałamucę\n",
      "  spędzić gdzieś zbyt wiele czasu\n",
      "\n",
      "oplewiałabyś\n",
      "  regionalnie: opielać\n",
      "\n",
      "trzepotem\n",
      "  1. szybkie ruchy czegoś na wietrze;\n",
      "  2. odgłos trzepotania;\n",
      "  3. mocne bicie serca\n",
      "\n",
      "związani\n",
      "  1. wiążąc, połączyć końce liny, sznurka, nici itp.; \n",
      "  2. unieruchomić kogoś, wiążąc mu nogi i ręce; \n",
      "  3. połączyć emocjonalnie kogoś z kimś lub czymś; \n",
      "  4. zobowiązać kogoś do przestrzegania tajemnicy, umowy itp.;   \n",
      "  5. o substancjach lub ich składnikach: utworzyć jednorodną całość\n",
      "\n",
      "związani\n",
      "  mający związek, coś wspólnego z kimś, z czymś\n",
      "\n",
      "subwencjonujcie\n",
      "  udzielać bezzwrotnej pomocy finansowej instytucji, organizacji, przedsiębiorstwu (rzadziej osobie) w celu poparcia określonej działalności; dotować, subsydiować, finansować\n",
      "\n",
      "deprecho\n",
      "  potocznie: depresja\n",
      "\n",
      "męczylibyśmy\n",
      "  1.\n",
      "  a) zadawać męki, sprawiać cierpienie\n",
      "  b) powodować zmęczenie, nudzić, nużyć, zadręczać\n",
      "  c) pot. robić coś z wysiłkiem albo przez dłuższy czas bez większych rezultatów\n",
      "  2. męczyć się:\n",
      "  a) cierpieć\n",
      "  b) trudzić się, biedzić się (nad czymś)\n",
      "\n",
      "obyczajowych\n",
      "  przymiotnik od: obyczaj, np. powieść obyczajowa\n",
      "\n",
      "romancy\n",
      "  1. utwór epicko-liryczny wykorzystujący fragmenty dawnych epopei, pokrewny balladzie;\n",
      "  2. sentymentalny utwór o prostej, zwrotkowej budowie, popularny pod koniec XVIII wieku; romanza\n",
      "\n",
      "niewydumywania\n",
      "  wymyślać\n",
      "\n",
      "bajzelek\n",
      "  zdrobnienie od: bajzel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_definitions = fetch_definitions(words_sample_rdd)\n",
    "\n",
    "for word, definition in word_definitions.collect():\n",
    "  print(word)\n",
    "  print(\" \", definition.replace(\"\\n\", \"\\n  \"))\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5kU5xyxIZH6"
   },
   "source": [
    "### Additional exercise:\n",
    " \n",
    "Print words from `words_sample_rdd` for which no definition was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "0TQ6kvNnyIOn"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def words_without_any_definition(words: RDD[str], word_definitions: RDD[Tuple[str, str]]) -> RDD[str]:\n",
    "  return words.map(lambda word: (word, 'S')).union(\n",
    "      word_definitions.map(lambda word_definition: (word_definition[0], 'D'))\n",
    "  ).groupByKey().flatMap(lambda word_tags: [word_tags[0]] if 'S' in word_tags[1] and 'D' not in word_tags[1] else [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NHTv7Y8z0WN",
    "outputId": "52359389-82f7-405d-d863-45891f94092a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words without any definition: ['elektryzacyj', 'obsypcież', 'rozwlekana']\n"
     ]
    }
   ],
   "source": [
    "print(f\"words without any definition: {words_without_any_definition(words_sample_rdd, word_definitions).collect()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jptMQSHLK4l"
   },
   "source": [
    "## Homework 1: Set union, intersection and difference\n",
    "\n",
    "Given two sets in `RDD` format calculate their union, intersection and difference.\n",
    "\n",
    "Note: you can assume that there are no duplicates in given `RDD`-s. It is part of the exercise to make sure there will be no duplicates in the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "RvLdtTpMLIi2"
   },
   "outputs": [],
   "source": [
    "from pyspark import RDD\n",
    "from typing import TypeVar\n",
    "\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "# calculates: a ∪ b\n",
    "def union(a: RDD[T], b: RDD[T]) -> RDD[T]:\n",
    "  union = a.map(lambda x: (x, 'A'), preservesPartitioning=True)\\\n",
    "      .union(b.map(lambda x: (x, 'B'), preservesPartitioning=True))\n",
    "\n",
    "  elements_in_union = union.groupByKey().mapValues(len).map(\n",
    "      lambda x: x[0]\n",
    "  )\n",
    "\n",
    "  return elements_in_union\n",
    "\n",
    "# calculates: a ∩ b\n",
    "def intersection(a: RDD[T], b: RDD[T]) -> RDD[T]:\n",
    "  union = a.map(lambda x: (x, 'A'), preservesPartitioning=True)\\\n",
    "      .union(b.map(lambda x: (x, 'B'), preservesPartitioning=True))\n",
    "\n",
    "  elements_in_intersection = union.groupByKey().mapValues(len).filter(\n",
    "      lambda x : x[1] % 2 == 0\n",
    "  ).map(\n",
    "      lambda x: x[0]\n",
    "  )\n",
    "\n",
    "  return elements_in_intersection\n",
    "\n",
    "# calculates: a - b\n",
    "def difference(a: RDD[T], b: RDD[T]) -> RDD[T]:\n",
    "  union = a.map(lambda x: (x, 'A'), preservesPartitioning=True)\\\n",
    "      .union(b.map(lambda x: (x, 'B'), preservesPartitioning=True))\n",
    "\n",
    "  elements_in_difference = union.groupByKey().flatMap(\n",
    "      lambda num_cntr: [num_cntr[0]] if 'A' in num_cntr[1] and 'B' not in num_cntr[1] else []\n",
    "      )\n",
    "\n",
    "  return elements_in_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCSce9caNGaG",
    "outputId": "0f093c7b-50ad-4142-a4f6-84eef0c864d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 1, 5, 2, 3],\n",
       " [4, 3],\n",
       " [1, 2],\n",
       " [2, 4, 1, 3],\n",
       " [2, 4, 1, 3],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [2, 4, 1, 3],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sc.parallelize([1, 2, 3, 4])\n",
    "b = sc.parallelize([3, 4, 5])\n",
    "\n",
    "[\n",
    "    union(a, b).collect(),\n",
    "    intersection(a, b).collect(),\n",
    "    difference(a, b).collect(),\n",
    "    union(a, sc.emptyRDD()).collect(),\n",
    "    union(sc.emptyRDD(), a).collect(),\n",
    "    union(sc.emptyRDD(), sc.emptyRDD()).collect(),\n",
    "    intersection(a, sc.emptyRDD()).collect(),\n",
    "    intersection(sc.emptyRDD(), a).collect(),\n",
    "    intersection(sc.emptyRDD(), sc.emptyRDD()).collect(),\n",
    "    difference(a, sc.emptyRDD()).collect(),\n",
    "    difference(sc.emptyRDD(), a).collect(),\n",
    "    difference(sc.emptyRDD(), sc.emptyRDD()).collect()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0vFtIIvOFUv"
   },
   "source": [
    "## Homework 2: Join\n",
    "\n",
    "Write a function calculating natural join of two relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Z4TVOGIGOVBL"
   },
   "outputs": [],
   "source": [
    "from pyspark import RDD\n",
    "from typing import Tuple, TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "U = TypeVar('U')\n",
    "V = TypeVar('V')\n",
    "\n",
    "# calculates all triples (x, y, z) such that (x,y)∈r and (y,z)∈s\n",
    "def join(r: RDD[Tuple[T, U]], s: RDD[Tuple[U, V]]) -> RDD[Tuple[T, U, V]]:\n",
    "  r = r.map(lambda x: [x[1], x[0]])\n",
    "  join = r.join(s)\n",
    "  join = join.map(lambda x: [x[1][0], x[0], x[1][1]])\n",
    "  return join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AoS6gbOgOok-",
    "outputId": "9ed9ff20-306c-4ac2-c0c6-aaa432d66e55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 'b', 12], [1, 'b', 12], [1, 'a', 12], [1, 'a', 22]]\n"
     ]
    }
   ],
   "source": [
    "a = sc.parallelize([(1, 'a'), (0, 'b'), (1, 'b')])\n",
    "b = sc.parallelize([('a', 12), ('a', 22), ('b', 12), ('c', 8)])\n",
    "\n",
    "print(join(a, b).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksT9dLxgl9je"
   },
   "source": [
    "<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
