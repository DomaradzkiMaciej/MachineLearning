{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Copy of GSN/DNN 2021/22 Exam - Task 1 - pixels.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imporant pixels\n",
    "\n",
    "You are given a pipeline that trains a fully convolutional autoencoder on the MNIST dataset. The model should train in under 2 minutes and give decent results (mean reconstruction loss <35).\n",
    "\n",
    "Your task is to write a function that for a given input image and output pixel coordinates produces a list of input pixels that have non-zero contribution to the value of the output pixel. You should measure each pixel's contribution by setting it to the minimal and maximal value over the whole image.\n"
   ],
   "metadata": {
    "id": "5Z7Hz3cmGYlx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training pipeline (DO NOT CHANGE THIS SECTION)"
   ],
   "metadata": {
    "id": "omLaGEc4aZHO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import typing\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)"
   ],
   "metadata": {
    "id": "OywVSurCbfNz"
   },
   "execution_count": 102,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 5\n",
    "batch_size = 250\n",
    "learning_rate = 1e-2\n",
    "log_interval = 40"
   ],
   "metadata": {
    "id": "1Cd2k4MGbkkx"
   },
   "execution_count": 103,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Binarize:\n",
    "    def __call__(self, sample):\n",
    "        return torch.bernoulli(sample)\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    Binarize(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train = MNIST('./data', train=True, transform=img_transform, download=True)\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test = MNIST('./data', train=False, transform=img_transform, download=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
   ],
   "metadata": {
    "id": "PUCzv721bknZ"
   },
   "execution_count": 104,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "            1,\n",
    "            16,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=1,\n",
    "            stride=1,\n",
    "            bias=False,\n",
    "        ),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Conv2d(\n",
    "            16,\n",
    "            32,\n",
    "            kernel_size=(4, 4),\n",
    "            padding=1,\n",
    "            stride=2,\n",
    "            bias=False,),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Conv2d(\n",
    "            32,\n",
    "            64,\n",
    "            kernel_size=(4, 4),\n",
    "            padding=1,\n",
    "            stride=2,\n",
    "            bias=False,),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                64,\n",
    "                32,\n",
    "                7, \n",
    "                2, \n",
    "                0, \n",
    "                bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                32,\n",
    "                16,\n",
    "                3, \n",
    "                1, \n",
    "                0, \n",
    "                bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                16,\n",
    "                8,\n",
    "                5, \n",
    "                1, \n",
    "                0, \n",
    "                bias=False),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                8,\n",
    "                1,\n",
    "                4, \n",
    "                1, \n",
    "                0, \n",
    "                bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ],
   "metadata": {
    "id": "KpeNB3KhRTvt"
   },
   "execution_count": 105,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.mse_loss(output, data, reduction=\"sum\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / data.size(0)))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.mse_loss(output, data, reduction='sum').item()  # sum up batch loss\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))\n",
    "\n"
   ],
   "metadata": {
    "id": "1n09n8PVWpR8"
   },
   "execution_count": 106,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = FCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch, log_interval)\n",
    "    test(model, device, test_loader)\n"
   ],
   "metadata": {
    "id": "0I3woOWcSBPu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "813b9c58-b4a6-4deb-9b66-588232f1ab0b"
   },
   "execution_count": 107,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 1198.498000\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 197.168625\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 149.806500\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 128.390172\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 101.429336\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 100.744469\n",
      "\n",
      "Test set: Average loss: 84.7261\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 84.302820\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 77.431383\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 79.398766\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 73.409070\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 64.332305\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 70.229250\n",
      "\n",
      "Test set: Average loss: 62.6196\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 61.528266\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 56.603125\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 55.655973\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 55.252437\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 59.231168\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 49.030203\n",
      "\n",
      "Test set: Average loss: 49.5720\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 50.025410\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 47.430266\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 49.612148\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 44.921391\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 43.608871\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 40.089797\n",
      "\n",
      "Test set: Average loss: 40.6579\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 39.361594\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 36.999672\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 36.042031\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 38.877539\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 29.206482\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 31.062041\n",
      "\n",
      "Test set: Average loss: 36.7192\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Important pixels"
   ],
   "metadata": {
    "id": "wg8A9DuMaT91"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "input_batch = next(iter(train_loader))[0][0,:].unsqueeze(0)\n",
    "input_batch = input_batch.to(device)\n",
    "plt.imshow(input_batch[0, :].cpu().detach().squeeze().numpy())"
   ],
   "metadata": {
    "id": "N-QwwJ77jB3T",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "outputId": "2ef113e7-e943-488a-cfbc-9ed80374b157"
   },
   "execution_count": 108,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa7de7e5450>"
      ]
     },
     "metadata": {},
     "execution_count": 108
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "plt.imshow(model(input_batch)[0, :].cpu().detach().squeeze().numpy())"
   ],
   "metadata": {
    "id": "mNf7bMGnaLUt",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "outputId": "04ed0afc-8abb-4a32-f25d-6e73bdb197f1"
   },
   "execution_count": 109,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa7de6cc810>"
      ]
     },
     "metadata": {},
     "execution_count": 109
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def important_pixels(input_batch: torch.Tensor, model: torchvision.models.segmentation.fcn.FCN, device: torch.device, coordinates: typing.Tuple[int, int]) -> typing.Set[typing.Tuple[int,int]]: \n",
    "    model = model.to(device)\n",
    "    input_batch = input_batch.to(device)\n",
    "\n",
    "    ################################\n",
    "\n",
    "    coord_y, coord_x = coordinates\n",
    "    important = []\n",
    "    for y in range(28):\n",
    "        for x in range(28):\n",
    "            clone = input_batch.clone()\n",
    " \n",
    "            clone[:, :, y, x] = -1\n",
    "            out1 = model(clone)[0, 0, coord_y, coord_x]\n",
    "            clone[:, :, y, x] = 1\n",
    "            out2 = model(clone)[0, 0, coord_y, coord_x]\n",
    "\n",
    "            if out1 != out2:\n",
    "                important.append((y, x))\n",
    "\n",
    "    return set(important)\n",
    "\n",
    "    ################################\n",
    "\n"
   ],
   "metadata": {
    "id": "T4xPxBueF7DZ"
   },
   "execution_count": 110,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "checked_pixel = (0, 0)\n",
    "pixels = important_pixels(input_batch, model, device, checked_pixel)"
   ],
   "metadata": {
    "id": "XDC6r9pzIWrX"
   },
   "execution_count": 111,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "input_image_numpy = input_batch[0, :].cpu().detach().squeeze().numpy()\n",
    "\n",
    "for pixel in pixels:\n",
    "    input_image_numpy[pixel[0], pixel[1]] = 0.25\n",
    "\n",
    "input_image_numpy[checked_pixel[0], checked_pixel[1]] = 0.75\n",
    "\n",
    "plt.imshow(input_image_numpy)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "sDcpODGUkY1v",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "outputId": "50aa4f03-5aaf-4541-f0ef-eed1d57f6ff4"
   },
   "execution_count": 112,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAADwUlEQVR4nO3dMWrbYBiAYTvkFCWHaA9ROnYIPU2PFMhecolSyNi1x4g6B2TZsRLrtfQ8o7XIhpcP/PFL+2EYdkDPzdI3AIwTJ0SJE6LECVHihKjbqYuPf79M/pX788/3972biLv756VvgQ15ennYj31uckKUOCFKnBAlTogSJ0SJE6LECVGTe8617jHhGpicECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oSo26VvYIt+/ft98Nq3T58veCeUmZwQJU6IEidEiROixAlR4oQoq5SYqTXLbmfVsiUmJ0SJE6LECVHihChxQpQ4IUqcEDW557y7f77UfazKsV3llDXvMe1w38bkhChxQpQ4IUqcECVOiBInRIkTopznjNnyLtAjQ18zOSFKnBAlTogSJ0SJE6LECVHihCh7zjPMOa8JpzI5IUqcECVOiBInRIkTosQJUeKEKHvOMxw7W7jVM5n2v+/L5IQocUKUOCFKnBAlTogSJ0RZpZCx1hXTuUxOiBInRIkTosQJUeKEKHFClDghyp7zDHOPRnnVHacwOSFKnBAlTogSJ0SJE6LECVHihCh7zhFLPuJxy4+XtP99zeSEKHFClDghSpwQJU6IEidEiROi7Dk52dxXH/I2JidEiROixAlR4oQocUKUOCFKnBBlzzlizfu8jzwXuebfbQkmJ0SJE6LECVHihChxQpQ4IcoqZcSSf/lf8yMg5/5u1/zdP4LJCVHihChxQpQ4IUqcECVOiBInRO2HYTh48evNj8MXN+zYPs++btycPeiaf9Onl4f92OcmJ0SJE6LECVHihChxQpQ4IUqcEOU85xnWvHOjw+SEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0Q5MsbFHDtqN/XozC0+jtTkhChxQpQ4IUqcECVOiBInRIkTouw5uZg5rwDcIpMTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTohynpOLmfPc2i0yOSFKnBAlTogSJ0SJE6LECVHihCh7TjLW+I7NOUxOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtR+GIal7wEYYXJClDghSpwQJU6IEidEiROi/gMnKGQ4DlHk9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "nnLFi_E8oJtg"
   },
   "execution_count": 112,
   "outputs": []
  }
 ]
}